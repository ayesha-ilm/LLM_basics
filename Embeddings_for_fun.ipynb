{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M2pb1Kwh2As"
      },
      "source": [
        "## Embeddings and Sentence Classification "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzMUF5eHh2Aw",
        "outputId": "0e265fdd-24ea-4b55-ecaf-1b7334d323ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gpt4all in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2023.11.17)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import  WordNetLemmatizer\n",
        "import gensim.downloader as api\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "!pip install gpt4all\n",
        "from gpt4all import Embed4All\n",
        "\n",
        "!pip install torch==2.1.0\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAjg50qhh2Ax"
      },
      "source": [
        "## Exploring Embeddings\n",
        "\n",
        "Put simply, Embeddings are fixed-size **dense** vector representations of tokens in natural language. This means you can represent words as vectors, sentences as vectors, even other entities like entire graphs as vectors.\n",
        "\n",
        "So what really makes them different from something like One-Hot vectors?\n",
        "\n",
        "What's special is that they have semantic meaning baked into them. This means you can model relationships between entities in text, which itself leads to a lot of fun applications. All modern architectures make use of Embeddings in some way.\n",
        "\n",
        "We will be using *pretrained* Embeddings: this means that we will be using Embeddings that have already been trained on a large corpus of text. This is because training Embeddings from scratch is a very computationally expensive task, and we don't have the resources to do so. Fortunately, there were some good samaritans who have already done this for us, and we can use their publicly available Embeddings for our own tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjxoI1FVh2Ax",
        "outputId": "01845807-4070-4b2b-d559-f258130b8808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done loading word2vec model!\n"
          ]
        }
      ],
      "source": [
        "corpus = api.load('text8')\n",
        "w2vmodel = Word2Vec(corpus)\n",
        "\n",
        "print(\"Done loading word2vec model!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZwLqV-Wh2Ax"
      },
      "source": [
        "Now that we've loaded in the Embeddings, we can create an Embedding **layer** in PyTorch, `nn.Embedding`, that will perform the processing step for us.\n",
        "\n",
        "Note in the following cell how there is a given **vocab size** and **embedding dimension** for the model: this is important to note because some sets of Embeddings may be defined for a large set of words (a large vocab), whereas older ones perhaps have a smaller set (a small vocab); the Embedding dimension essentially tells us how many *features* have been learned for a given word, that will allow us to perform further processing on top of."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzvFi9juh2Ay",
        "outputId": "2b22199e-f33c-4b4c-9b0c-a9f04e91154c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size: 71290\n",
            "Some of the words in the vocabulary:\n",
            "['the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero', 'nine', 'two']\n",
            "Embedding dimension: 100\n"
          ]
        }
      ],
      "source": [
        "# Define embedding layer using gensim\n",
        "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(w2vmodel.wv.vectors))\n",
        "\n",
        "# Get some information from the w2vmodel\n",
        "print(f\"Vocab size: {len(w2vmodel.wv.key_to_index)}\")\n",
        "\n",
        "print(f\"Some of the words in the vocabulary:\\n{list(w2vmodel.wv.key_to_index.keys())[:10]}\")\n",
        "\n",
        "print(f\"Embedding dimension: {w2vmodel.wv.vectors.shape[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls725V2hh2Ay"
      },
      "source": [
        "Now, for a demonstration, we instantiate two words, turn them into numbers (encoding them via their index in the vocab), and pass them through the Embedding layer.\n",
        "\n",
        "Note how the resultant Embeddings both have the same shape: 1 word, and 100 elements in the vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BZDNLqUh2Ay",
        "outputId": "93553b04-b788-4de4-fee7-ce03165c3938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding Shape for 'king': torch.Size([1, 100])\n",
            "Embedding Shape for 'queen': torch.Size([1, 100])\n"
          ]
        }
      ],
      "source": [
        "# Take two words and get their embeddings\n",
        "word1 = \"king\"\n",
        "word2 = \"queen\"\n",
        "\n",
        "def word2vec(word):\n",
        "    return embedding_layer(torch.LongTensor([w2vmodel.wv.key_to_index[word]]))\n",
        "\n",
        "king_embedding = word2vec(word1)\n",
        "queen_embedding = word2vec(word2)\n",
        "\n",
        "print(f\"Embedding Shape for '{word1}': {king_embedding.shape}\")\n",
        "print(f\"Embedding Shape for '{word2}': {queen_embedding.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK32Fr4Th2Az"
      },
      "source": [
        "When we have vectors whose scale is arbitrary, one nice way to measure how *similar* they are is with the Cosine Similarity measure.\n",
        "\n",
        "\n",
        "$$ \\text{Cosine Similarity}(\\mathbf{u},\\mathbf{v}) = \\frac{\\mathbf{u} \\cdot \\mathbf{v}}{\\|\\mathbf{u}\\| \\|\\mathbf{v}\\|} $$\n",
        "\n",
        "\n",
        "We can apply this idea to our Embeddings. To see how \"similar\" two words are to the model, we can generate their Embeddings and take the Cosine Similarity of them. This will be a number between -1 and 1 (just like the range of the cosine function). When the number is close to 0, the words are not similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKZLeIAHh2Az",
        "outputId": "007ca8ab-16af-41c2-93a5-b0d86b4c8dd9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between 'king' and 'queen': 0.699151337146759\n",
            "Similarity between 'king' and 'king': 1.0000001192092896\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    '''\n",
        "    Computes the cosine similarity between two vectors\n",
        "    '''\n",
        "    dot_product = torch.dot(torch.squeeze(vec1), torch.squeeze(vec2))\n",
        "    norm_vec1 = torch.norm(vec1)\n",
        "    norm_vec2 = torch.norm(vec2)\n",
        "\n",
        "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
        "    return similarity.item()\n",
        "\n",
        "def compute_word_similarity(word1, word2):\n",
        "    '''\n",
        "    Takes in two words, computes their embeddings and returns the cosine similarity\n",
        "    '''\n",
        "\n",
        "    with torch.no_grad():\n",
        "        embedding_word1 = embedding_layer(torch.tensor([w2vmodel.wv.key_to_index[word1]]))\n",
        "        embedding_word2 = embedding_layer(torch.tensor([w2vmodel.wv.key_to_index[word2]]))\n",
        "        similarity = cosine_similarity(embedding_word1, embedding_word2)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "word1 = 'king'\n",
        "word2 = 'queen'\n",
        "word3 = 'king'\n",
        "print(f\"Similarity between '{word1}' and '{word2}': {compute_word_similarity(word1, word2)}\")\n",
        "print(f\"Similarity between '{word1}' and '{word3}': {compute_word_similarity(word1, word3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BipJxQ4Vh2Az"
      },
      "outputs": [],
      "source": [
        "del embedding_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcsrBMHKh2Az"
      },
      "source": [
        "## Sentence Classification Classification with Sentence Embeddings \n",
        "\n",
        "Now let's move on to an actual application: classifying whether a tweet is about a real disaster or not. As you can imagine, this could be a valuable model when monitoring social media for disaster relief efforts.\n",
        "\n",
        "Since we are using Sentence Embeddings, we want something that will take in a sequence of words and throw out a single fixed-size vector. For this task, we will make use of an LLM via the `gpt4all` library.\n",
        "\n",
        "This library will allow us to generate pretrained embeddings for sentences, that we can use as **features** to feed to any classifier of our choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1etrijPsh2Az",
        "outputId": "ff3b87b1-bf04-45df-8b8f-0de0f941e97a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set shape: (6090,) (6090,)\n",
            "validation set shape: (1523,) (1523,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df = pd.read_csv(\"/content/disaster_tweets.csv\")\n",
        "df = df[[\"text\", \"target\"]]\n",
        "\n",
        "\n",
        "X = df[\"text\"]\n",
        "y = df[\"target\"]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"train set shape:\", X_train.shape, y_train.shape)\n",
        "print(\"validation set shape:\", X_val.shape, y_val.shape)\n",
        "\n",
        "# print(X_train.shape, X_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUAAKbkWh2A0"
      },
      "source": [
        "Before jumping straight to Embeddings, since our data is sourced from the cesspool that is Twitter, we should probably do some cleaning. This can involve the removal of URLs, punctuation, numbers that don't provide any meaning, stopwords, and so on.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVAlfVTvh2A0"
      },
      "source": [
        "Now for the fun part, creating our Embeddings!\n",
        "\n",
        "This functionality makes use of a model called [Sentence-BERT](https://arxiv.org/abs/1908.10084). This is a Transformer-based model that has been trained on a large corpus of text, and is able to generate high-quality Sentence Embeddings for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6_3tFlwh2A0",
        "outputId": "0db40f6f-5bb7-4439-dd12-3e1fee13ed7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set shape after cleaning: (5872,) (5872,)\n",
            "validation set shape after cleaning: (1471,) (1471,)\n",
            "4996    courageous honest analysis need use atomic bom...\n",
            "3263    zachzaidman thescore wld b shame golf cart bec...\n",
            "4907    tell barackobama rescind medals honor given us...\n",
            "2855    worried ca drought might affect extreme weathe...\n",
            "4716    youngheroesid lava blast amp power red panther...\n",
            "7538    wreckage conclusively confirmed mh malaysia pm...\n",
            "3172    builder dental emergency ruined plan emotional...\n",
            "3932    bmx issues areal flood advisory shelby al till...\n",
            "5833       wisenews chinas stock market crash gems rubble\n",
            "7173    robertoneill getting hit foul ball sitting har...\n",
            "Name: text, dtype: object 4996    1\n",
            "3263    0\n",
            "4907    1\n",
            "2855    1\n",
            "4716    0\n",
            "7538    1\n",
            "3172    1\n",
            "3932    1\n",
            "5833    1\n",
            "7173    0\n",
            "Name: target, dtype: int64\n",
            "2644            new weapon cause unimaginable destruction\n",
            "2227    famping things gishwhes got soaked deluge goin...\n",
            "5448    dt georgegalloway rt gallowaymayor   the col p...\n",
            "132     aftershock back school kick great want thank e...\n",
            "6845    response trauma children addicts develop defen...\n",
            "5559    calumsos look like got caught rainstorm amazin...\n",
            "1765    favorite lady came volunteer meeting hopefully...\n",
            "1817    brianroemmele ux fail emv people want insert r...\n",
            "6810        cant find ariana grande shirt fucking tragedy\n",
            "4398           murderous story america  s first hijacking\n",
            "Name: text, dtype: object 2644    1\n",
            "2227    0\n",
            "5448    1\n",
            "132     0\n",
            "6845    0\n",
            "5559    0\n",
            "1765    1\n",
            "1817    1\n",
            "6810    0\n",
            "4398    1\n",
            "Name: target, dtype: int64\n",
            "Text data type: object\n",
            "Labels data type: int64\n",
            "NaN values in text data: False\n",
            "NaN values in labels: False\n",
            "Special characters in text data: Series([], Name: text, dtype: object)\n",
            "Leading/trailing spaces in text data: 2968     jeesss  ethereal  hello  yeah someone drownin...\n",
            "964       new ladies shoulder tote handbag faux leathe...\n",
            "977        new ladies shoulder tote handbag faux leath...\n",
            "2939                   itsdanie  noooo almost drowned tho\n",
            "7564      ohhmyjoshh stevenrulles gonna thinking gets ...\n",
            "2716      richmond coaches devastated hear death secon...\n",
            "2586                       reddevillife  manutd destroyed\n",
            "2881           gaabyx got purple activist thought drought\n",
            "6105      if lost amp alone sinking like stone carry on  \n",
            "1630      thehighfessions friend came school blastedi ...\n",
            "3187      based georgie yo forreal need like emergency...\n",
            "5513      scrambledeggs calling kia gets banned quaran...\n",
            "6243      lordbrathwaite everyone ahh hate snow lol u ...\n",
            "6932     charleyisqueen yeah well maybe barber didnt c...\n",
            "6563      bbcwomanshour setsuko thurlow survived hiros...\n",
            "3815     we help   says denver firefighter working cur...\n",
            "3971      bbcengland burst water main causes major flo...\n",
            "7479             pokemoncards  icequeenfroslas wreck sale\n",
            "1303       bulletproof black like funeral world around...\n",
            "2309                 stiiilo still got video u demolished\n",
            "4417     good samaritans   shot horror hijacking chat ...\n",
            "1628      mgnafrica  pinf    correction tent collapse ...\n",
            "1356     minimehh cjoyner must overlooking burning bui...\n",
            "2723      richmond coaches devastated hear death secon...\n",
            "4402     good samaritans   shot horror hijacking johan...\n",
            "2725      richmond coaches devastated hear death secon...\n",
            "2785     only sea knows many dead msf sea last disaste...\n",
            "1798                   chelsdelong kendra leigh ill crash\n",
            "7351                     wildfire   bruh thats lady mulan\n",
            "1014      macdaddy leo caption needed freshman nigga s...\n",
            "906                   itsmegss  think well bloody barking\n",
            "1418      the road power paved hypocrisy casualties  f...\n",
            "2800                               im architect disaster \n",
            "704       srajapakse   thank missy thought suited blaz...\n",
            "3521      little boy  affected people hiroshima    eye...\n",
            "4422     ransomware   holds bc man  s computer files h...\n",
            "6325                         stretcher  min speaker deck \n",
            "1828                              bug almost crashed euro\n",
            "4156      for know plans you  declares lord   plans pr...\n",
            "2128      lolgop  cases voter fraud year need new laws...\n",
            "673      itzsteven xdojjjj whopper jr  huh leo started...\n",
            "6899       keits liva gotta get gold chain youll under...\n",
            "3584                             asianshawtyy im sorry im\n",
            "455        blasts accused yeda yakub dies karachi hear...\n",
            "412               dc cloudy goldrush hate white people mo\n",
            "4929      retweet follow rt followback gain follow gan...\n",
            "971        new ladies shoulder tote handbag faux leath...\n",
            "1069                 dylanmcclure working zumiez location\n",
            "6170              dangdaddy sirens telling get ready turn\n",
            "6310                         stretcher  min speaker deck \n",
            "2919     dmerida tears drowned terrible taste also nat...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# TODO: Clean the sentences (5 marks)\n",
        "\n",
        "\n",
        "# TODO: Fill out the following functions, adding more if desired\n",
        "\n",
        "def lowercase(txt):\n",
        "    return txt.lower()\n",
        "\n",
        "def remove_punctuation(txt):\n",
        "    return re.sub(r'[^\\w\\s]', '', txt)\n",
        "\n",
        "def remove_stopwords(txt):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = txt.split()\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "def remove_numbers(txt):\n",
        "    return re.sub(r'\\d+', '', txt)\n",
        "\n",
        "def remove_url(txt):\n",
        "    return re.sub(r'http\\S+', '', txt)\n",
        "\n",
        "def normalize_sentence(txt):\n",
        "    '''\n",
        "    Aggregates all the above functions to normalize/clean a sentence\n",
        "    '''\n",
        "    txt = lowercase(txt)\n",
        "    txt = remove_url(txt)\n",
        "    txt = remove_punctuation(txt)\n",
        "    txt = remove_stopwords(txt)\n",
        "    txt = remove_numbers(txt)\n",
        "    txt = txt.strip()\n",
        "    txt = re.sub(r'[^a-zA-Z0-9\\s]', ' ', txt)\n",
        "\n",
        "\n",
        "    return txt\n",
        "\n",
        "X_train_cleaned = X_train.apply(normalize_sentence)\n",
        "X_val_cleaned = X_val.apply(normalize_sentence)\n",
        "\n",
        "min_sentence_length = 20\n",
        "X_train_filtered = X_train_cleaned[X_train_cleaned.apply(len) >= min_sentence_length]\n",
        "y_train_filtered = y_train[X_train_cleaned.apply(len) >= min_sentence_length]\n",
        "X_val_filtered = X_val_cleaned[X_val_cleaned.apply(len) >= min_sentence_length]\n",
        "y_val_filtered = y_val[X_val_cleaned.apply(len) >= min_sentence_length]\n",
        "\n",
        "\n",
        "print(\"train set shape after cleaning:\", X_train_filtered.shape, y_train_filtered.shape)\n",
        "print(\"validation set shape after cleaning:\", X_val_filtered.shape, y_val_filtered.shape)\n",
        "print(X_train_filtered[:10], y_train_filtered[:10])\n",
        "print(X_val_filtered[:10], y_val_filtered[:10])\n",
        "\n",
        "print(\"Text data type:\", X_train_cleaned.dtype)\n",
        "print(\"Labels data type:\", y_train_filtered.dtype)\n",
        "print(\"NaN values in text data:\", X_train_cleaned.isnull().any())\n",
        "print(\"NaN values in labels:\", y_train_filtered.isnull().any())\n",
        "print(\"Special characters in text data:\", X_train_cleaned[X_train_cleaned.str.contains(r'[^a-zA-Z0-9\\s]')])\n",
        "print(\"Leading/trailing spaces in text data:\", X_train_cleaned[X_train_cleaned.str.match(r'^\\s|\\s$')])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-RJ4JLfh2A0",
        "outputId": "22e1a498-29d5-429a-fa5d-4ebf053115a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 45.9M/45.9M [00:03<00:00, 13.2MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output structure: <class 'list'>\n",
            "[-0.04516274109482765, 0.12774068117141724, -0.03049377351999283, 0.000782765622716397, 0.013275389559566975, 0.016861621290445328, 0.055261604487895966, 0.008617403917014599, -0.02639164589345455, 0.007780713029205799, 0.042924538254737854, -0.01940971612930298, 0.03689299523830414, 0.03972916677594185, 0.011344856582581997, 0.01799238659441471, -0.02071196399629116, 0.016547061502933502, -0.010986067354679108, -0.02933647856116295, -0.07392047345638275, 0.046137116849422455, 0.07390392571687698, -0.002076385309919715, -0.014989830553531647, 0.014138161204755306, 0.06163441017270088, 0.040662702172994614, -0.012586784549057484, -0.01801145263016224, 0.0339195653796196, 0.046742022037506104, 0.099168561398983, 0.0014147365000098944, 0.04102880880236626, 0.007911625318229198, 0.016119474545121193, 0.02185426838696003, 0.01848200522363186, -0.09288961440324783, -0.14541377127170563, 0.0007321782759390771, 0.022364992648363113, 0.025120049715042114, -0.015684504061937332, 0.010132750496268272, -0.039122093468904495, -0.06490413099527359, -0.006049247924238443, -0.05121367424726486, -0.01571008935570717, 0.009114047512412071, -0.024824194610118866, -0.1035577803850174, 0.07149553298950195, -0.05158635973930359, 0.04963028430938721, 0.02406461536884308, 0.04143989458680153, -0.02900528348982334, 0.021633503958582878, -0.0039467522874474525, -0.03726360574364662, -0.012030348181724548, 0.11517376452684402, 0.049946531653404236, 0.024991417303681374, 0.05576673522591591, 0.04589516669511795, 0.01370775792747736, 0.04773498326539993, -0.005135491490364075, 0.07262251526117325, -0.017100071534514427, -0.14665773510932922, -0.06425483524799347, 0.008512379601597786, -0.002746084937825799, 0.02636253647506237, 0.030657025054097176, -0.06782393157482147, -0.06121455878019333, -0.029765170067548752, 0.035197168588638306, -0.03665192052721977, -0.033636972308158875, -0.03486933559179306, -0.12279506772756577, 0.018491007387638092, 0.059652768075466156, -0.00943618081510067, 0.031047914177179337, 0.050403617322444916, 0.056896407157182693, 0.01205031294375658, -0.02000533603131771, -0.05139283835887909, -0.012712692841887474, -0.09406517446041107, 0.09537892788648605, 0.10810744017362595, 0.05996153503656387, -0.08211030811071396, -0.11806397140026093, -0.00031202458194456995, -0.07173649221658707, -0.0038098180666565895, -0.1298462301492691, -0.02611345425248146, 0.0479414239525795, -0.029055839404463768, -0.02978655882179737, -0.04469272121787071, -0.003299531526863575, 0.16108518838882446, -0.006345058791339397, 0.01820838823914528, 0.019898399710655212, -0.049156416207551956, -0.04474575072526932, 0.05472470074892044, -0.011643605306744576, -0.01880122907459736, 0.07265719771385193, -0.06634309887886047, -0.013224375434219837, 0.01998935267329216, 4.613044276151736e-33, 0.036065664142370224, 0.032103996723890305, -0.025061991065740585, 0.09542012214660645, -0.05997356399893761, -0.04376692324876785, -0.0008124000742100179, -0.050714071840047836, 0.0031478004530072212, 0.07471056282520294, 0.0030518476851284504, 0.05180337652564049, 0.01851361058652401, -0.03235890716314316, -0.04927360266447067, -0.015620183199644089, -0.062919981777668, 0.03907538950443268, 0.0045920321717858315, 0.026962900534272194, 0.0707995817065239, -0.003562693018466234, 0.002212229883298278, -0.03521931916475296, -0.003651367500424385, -0.015390527434647083, -0.038466453552246094, -0.017629683017730713, 0.00011505149450385943, 0.033298101276159286, -0.006325709167867899, -0.014086148701608181, -0.03347110003232956, -0.004044255241751671, 0.09279818832874298, -0.04829000309109688, -0.005786686670035124, -0.009491215460002422, -0.03154071792960167, -0.04986700415611267, -0.04380132630467415, -0.0021282555535435677, -0.08668412268161774, 0.03311874344944954, 0.11995919793844223, 0.06749485433101654, -0.03817382827401161, -0.09009969234466553, 0.07368212193250656, 0.023655874654650688, -0.07757207006216049, 0.01178903691470623, -0.01949148438870907, -0.012527791783213615, 0.036742549389600754, 0.021250160411000252, 0.028590263798832893, 0.06991363316774368, 0.014093412086367607, 0.04029640182852745, -0.01829596422612667, 0.022288978099822998, -0.09457295387983322, -0.06456347554922104, 0.005087776575237513, 0.009764598682522774, -0.16387291252613068, -0.038449257612228394, -0.04505510255694389, 0.019291536882519722, 0.017629556357860565, -0.007896783761680126, 0.014019385911524296, -0.029914841055870056, -0.012262450531125069, -0.05162493884563446, 0.050609853118658066, 0.0233820341527462, 0.05104880779981613, -0.07939846068620682, 0.05654224753379822, 0.03480362519621849, -0.04398231580853462, 0.006184493191540241, 0.03813508152961731, -0.028280435130000114, 0.03293473273515701, -0.04239349067211151, -0.008500480093061924, 0.0602201372385025, -0.039081960916519165, -0.0027253369335085154, 0.04594690352678299, -0.08945854753255844, -0.09178217500448227, -5.252962462246265e-33, -0.02284429594874382, 0.09647198766469955, -0.07868173718452454, 0.05551602318882942, 0.02263622172176838, 0.016932958737015724, -0.11096855998039246, 0.019438784569501877, 0.05377628654241562, 0.050995126366615295, 0.048484206199645996, -0.03331461548805237, 0.05014805495738983, -0.006645739544183016, -0.03868244215846062, -0.04461858794093132, 0.06258415430784225, -0.022221079096198082, -0.04953448846936226, 0.024628864601254463, 0.03028731793165207, -0.00340168341062963, -0.1043030321598053, -0.0648450255393982, -0.02349533513188362, 0.06190032511949539, -0.0003415479732211679, -0.01929524913430214, 0.0705762505531311, -0.051843833178281784, 0.07452157139778137, 0.0272050891071558, -0.07514132559299469, 0.021472668275237083, -0.0010282467119395733, -0.08166374266147614, 0.0516878217458725, 0.1048375740647316, -0.03301819786429405, -0.009297759272158146, -0.060411226004362106, 0.01621030643582344, -0.03863087296485901, -0.027043631300330162, -0.05646523833274841, -0.06867295503616333, -0.004952982999384403, -0.028505658730864525, -0.0015320160891860723, -0.02333536371588707, 0.0021999154705554247, -0.008607304655015469, 0.027420297265052795, -0.0162624754011631, 0.029165901243686676, -0.01750444620847702, -0.020020944997668266, 0.010476353578269482, 0.03955375775694847, 0.0113068213686347, 0.014622149057686329, -0.04722556099295616, -0.00437357509508729, 0.08431955426931381, 0.07813642919063568, -0.03644874691963196, -0.013061064295470715, 0.08849585801362991, -0.0804971233010292, 0.039903584867715836, -0.0007439333130605519, -0.007484646048396826, 0.06701532006263733, -0.012069136835634708, 0.08011121302843094, -0.03860645741224289, -0.09848688542842865, 0.01119223702698946, -0.006323919165879488, 0.011412309482693672, 0.05128362402319908, -0.005918544717133045, -0.06575014442205429, -0.0307718925178051, 0.029793716967105865, 0.007178711239248514, -0.022240394726395607, -0.05524599179625511, 0.04499351233243942, -0.024785198271274567, -0.03709577023983002, -0.07821381092071533, 0.07190197706222534, -0.007620427757501602, 0.007829919457435608, -2.2691706291766423e-08, -0.006725853309035301, -0.06082772836089134, 0.028411833569407463, -0.024770043790340424, 0.027236785739660263, 0.06774371862411499, -0.011374309659004211, -0.0718400850892067, -0.06752786040306091, -0.020076218992471695, 0.007649634499102831, 0.084492027759552, -0.09494167566299438, 0.09440858662128448, -0.06294392794370651, 0.03265737369656563, 0.048197321593761444, -0.06697303056716919, -0.032559964805841446, -0.021100623533129692, 0.013400225900113583, 0.022595873102545738, -0.08540496975183487, -0.01556550245732069, 0.025377361103892326, 0.12837739288806915, -0.02904415689408779, 0.06803136318922043, -0.04456286132335663, 0.030671056360006332, 0.0026565457228571177, 0.0033873359207063913, -0.05672290548682213, -0.06717909127473831, -0.04985705763101578, 0.08468186110258102, 0.06813127547502518, -0.027553575113415718, -0.042093921452760696, 0.010798526927828789, -0.1417289674282074, 0.08503959327936172, 0.0019115547183901072, 0.06006499379873276, 0.04372866824269295, 0.07810590416193008, -0.007144321221858263, 0.013432534411549568, -0.03217537701129913, 0.01995006389915943, -0.033520590513944626, -0.0359228178858757, -0.04761064425110817, 0.07121851295232773, 0.035659924149513245, 0.07722733169794083, 0.03896554931998253, 0.023044634610414505, -0.04594343528151512, 0.08824676275253296, 0.09153550118207932, 0.025122161954641342, -0.008759993128478527, -0.02128538489341736]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "feature_extractor = Embed4All()\n",
        "\n",
        "example_embedding = feature_extractor.embed(X_train_filtered.values[0])\n",
        "print(f\"Output structure: {type(example_embedding)}\")\n",
        "print(example_embedding)\n",
        "\n",
        "X_train_embeddings = [feature_extractor.embed(sentence) for sentence in X_train_filtered.values]\n",
        "\n",
        "\n",
        "X_val_embeddings = [feature_extractor.embed(sentence) for sentence in X_val_filtered.values]\n",
        "\n",
        "\n",
        "y_train_labels = y_train_filtered.values\n",
        "y_val_labels = y_val_filtered.values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pwpYh2cj4oV",
        "outputId": "f5d62cbb-0e92-459e-cf17-fe6ac30c3329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train_embeddings - type: <class 'list'>, shape: 5872\n",
            "X_val_embeddings - type: <class 'list'>, shape: 1471\n",
            "Element 0 - type: <class 'list'>, shape: 384\n",
            "y_train_labels - type: <class 'numpy.ndarray'>, shape: (5872,)\n",
            "y_val_labels - type: <class 'numpy.ndarray'>, shape: (1471,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train_embeddings - type: {type(X_train_embeddings)}, shape: {len(X_train_embeddings)}\")\n",
        "print(f\"X_val_embeddings - type: {type(X_val_embeddings)}, shape: {len(X_val_embeddings)}\")\n",
        "\n",
        "if X_train_embeddings:\n",
        "    print(f\"Element 0 - type: {type(X_train_embeddings[0])}, shape: {len(X_train_embeddings[0])}\")\n",
        "\n",
        "print(f\"y_train_labels - type: {type(y_train_labels)}, shape: {y_train_labels.shape}\")\n",
        "print(f\"y_val_labels - type: {type(y_val_labels)}, shape: {y_val_labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBpFnr_hh2A0"
      },
      "source": [
        "Now with our Embeddings ready, we can move on to the actual classification task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqlUB5Xzh2A0",
        "outputId": "8bb0a5e3-cc91-4cfe-daf7-08329a4914e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "validation accuracy (Logistic Regression): 0.7967\n",
            "classification report (Logistic Regression):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.83      0.82       829\n",
            "           1       0.78      0.75      0.76       642\n",
            "\n",
            "    accuracy                           0.80      1471\n",
            "   macro avg       0.79      0.79      0.79      1471\n",
            "weighted avg       0.80      0.80      0.80      1471\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "logreg_classifier = LogisticRegression(random_state=42)\n",
        "logreg_classifier.fit(X_train_embeddings, y_train_labels)\n",
        "y_val_pred_logreg = logreg_classifier.predict(X_val_embeddings)\n",
        "\n",
        "accuracy_logreg = accuracy_score(y_val_labels, y_val_pred_logreg)\n",
        "print(f\"validation accuracy (Logistic Regression): {accuracy_logreg:.4f}\")\n",
        "\n",
        "print(\"classification report (Logistic Regression):\")\n",
        "print(classification_report(y_val_labels, y_val_pred_logreg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy4-t5hEh2A0",
        "outputId": "c0fee71a-a32f-4a45-87ee-bbf8737b0d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentence 1: predicted class - 0, probability - 0.4323131968062236\n",
            "sentence 2: predicted class - 1, probability - 0.8999811074198404\n"
          ]
        }
      ],
      "source": [
        "def predict(sentence, clf):\n",
        "    '''\n",
        "    Takes in a sentence and returns the predicted class along with the probability\n",
        "    '''\n",
        "\n",
        "    cleaned_sentence = normalize_sentence(sentence)\n",
        "    encoded_sentence = feature_extractor.embed(cleaned_sentence)\n",
        "    encoded_sentence = np.array(encoded_sentence).reshape(1, -1)\n",
        "\n",
        "    predicted_class = clf.predict(encoded_sentence)[0]\n",
        "    probability = clf.predict_proba(encoded_sentence)[:, 1][0]\n",
        "\n",
        "    return predicted_class, probability\n",
        "\n",
        "sentence1 = \"I love the sunny weather today.\"\n",
        "sentence2 = \"There's heavy rain and thunder outside.\"\n",
        "\n",
        "class1, prob1 = predict(sentence1, logreg_classifier)\n",
        "class2, prob2 = predict(sentence2, logreg_classifier)\n",
        "\n",
        "print(f\"sentence 1: predicted class - {class1}, probability - {prob1}\")\n",
        "print(f\"sentence 2: predicted class - {class2}, probability - {prob2}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "bbe381b710e5d3541ca1e32a0f143d44d9fc319722adcf51c48d4250c2e9fef8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
